{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9507994e",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064720f",
   "metadata": {},
   "source": [
    "1] Increases the performance of network\n",
    "\n",
    "$\\rightarrow$ W/B update.\n",
    "\n",
    "$\\rightarrow$ Activation Function update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0653972",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{new} = w_{old} -  \\eta \\cdot \\frac{\\partial L}{\\partial w_{old}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc5fd8f",
   "metadata": {},
   "source": [
    "## **Types of Optimizers**\n",
    "\n",
    "### 1] Gradient Descent\n",
    "\n",
    " 1. Batch Gradient Descent\n",
    " 2. Stochastic Gradient Descent\n",
    " 3. Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760dc23",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Epochs} / \\text{Iterations}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabcd6a8",
   "metadata": {},
   "source": [
    "**Epochs:** Complete data set seen by the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497c938",
   "metadata": {},
   "source": [
    "$\n",
    "\\text{Epoch} \\longrightarrow \\text{the big cycle}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Iteration} \\longrightarrow \\text{the small cycle}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35489bb",
   "metadata": {},
   "source": [
    "#### 1. Batch Gradient Descent\n",
    "\n",
    "$$\n",
    "\\text{1000} \\longrightarrow \\text{Data points, Rows in Data}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050a16b",
   "metadata": {},
   "source": [
    "means,\n",
    "\n",
    "$$\n",
    "\\text{Epoch 1} \\longrightarrow  [ \\frac{\\text{1000 data points}}{\\text{1  Iteration}} ]\n",
    "$$\n",
    "$$\n",
    "\\text{Weights will update}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de96bf",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Epoch 2} \\longrightarrow [ \\frac{\\text{1000 data points}}{\\text{1  Iteration}} ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Weights will update}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39088e18",
   "metadata": {},
   "source": [
    "passing all data points at once and then weight updation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a4eca2",
   "metadata": {},
   "source": [
    "$Q.$ rather than 1000 data points i want to pass 1 billion data points what will happen ?\n",
    "\n",
    "$\\longrightarrow$ Let's consider our system has **8 GB RAM** to store 1 Billion data points, will get very common error **[OOM (out of memory error)]()**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a77cf",
   "metadata": {},
   "source": [
    "**<u>Advantages:</u>**\n",
    "\n",
    "- Convergence will happen\n",
    "\n",
    "**<u>Dis-advatnages:</u>**\n",
    "\n",
    "- Resource Intensive \n",
    "\n",
    "$$\n",
    "\\text{Huge Ram}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{CPU} \\longrightarrow \\text{RAM} \\\\\n",
    "\n",
    "\\text{GPU} \\longrightarrow \\text{V RAM}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f58aa5",
   "metadata": {},
   "source": [
    "Idea is that we cannot fit entire data once that is bad idea, we have to **break** it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ae0a6",
   "metadata": {},
   "source": [
    "$$\n",
    "[\\text{1 Epoch} = \\text{1 Iteration}] \\longrightarrow \\text{This is bad.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8195d",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "\n",
    "$$\n",
    "\\text{1000 data points} \\longrightarrow \\text{100 epochs} \\\\\n",
    "\\text{weight updation} \\longrightarrow \\text{100 times it will update}\n",
    "$$\n",
    "\n",
    "**How many weights ?**\n",
    "\n",
    "$$\n",
    "\\frac{1000}{weights} X \\frac{100}{updates}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{total weight updation} = 1,00,000\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d363ca4",
   "metadata": {},
   "source": [
    "#### 2. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d51c79",
   "metadata": {},
   "source": [
    "$ \\text{1 data point for 1 iteration}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02224fb0",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{if I have 1000 datapoints} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Epoch 1} - \n",
    "\\begin{cases}\n",
    "\\text{1 iteration} \\\\\n",
    "\\text{1 data point}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Epoch 1000} - \n",
    "\\begin{cases}\n",
    "\\text{1000 iteration} \\\\\n",
    "\\text{1000 data point}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026c449",
   "metadata": {},
   "source": [
    "**<u>Dis-Advantages:</u>**\n",
    "\n",
    "1. Time taking\n",
    "2. Resource wastage\n",
    "3. Jittery / Noise (osclillations in convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fde6db",
   "metadata": {},
   "source": [
    "**<u>Advantages:</u>**\n",
    "\n",
    "1. No Resource Issue [(OOM Issue)]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e0b90",
   "metadata": {},
   "source": [
    "#### 3. Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddea659",
   "metadata": {},
   "source": [
    "idea here is introduce a batch with batch size, (because we can't fit entire data in available **RAM**, so we devide data in batches, and load them accordingly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145e5a1",
   "metadata": {},
   "source": [
    "1. let's take 1000 data points \n",
    "\n",
    "$$\n",
    "\\text{Batch Size} \\longrightarrow \\text{100} \\\\\n",
    "\n",
    "\\text{iterations} \\longrightarrow \\text{10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e139c74",
   "metadata": {},
   "source": [
    "2. if Batch Size is 90\n",
    "\n",
    "$$\n",
    "\\text{Batch Size} \\longrightarrow \\text{90} \\\\\n",
    "\n",
    "\\text{iterations} \\longrightarrow \\text{11} \\\\\n",
    "\n",
    "990 = 11 \\text{iteration} \\\\\n",
    "\n",
    "\\text{left with 10 data points}\n",
    "$$\n",
    "\n",
    "for those 10 data points will perform 12<sup>th</sup> iteration in that will pass only those 10 data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c46f8d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Epoch 1} - \n",
    "\\begin{cases}\n",
    "\\text{iteration 1}\\\\\n",
    "\\text{Batch Size}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18baff",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\text{Total data points}}{\\text{Batch Size}} \n",
    "\\begin{cases}\n",
    "\\text{if integer then iterations,} \\\\\n",
    "\\text{otherwise integer + 1}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd80870",
   "metadata": {},
   "source": [
    "**<u>Advantages:</u>**\n",
    "\n",
    "1. Less Noise\n",
    "\n",
    "2. Convergence will happen\n",
    "\n",
    "3. Resource efficient\n",
    "\n",
    "4. takes less time compared to **SGD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80f1ce",
   "metadata": {},
   "source": [
    "**<u>Dis-Advantages:</u>**\n",
    "\n",
    "1. Noise exists\n",
    "\n",
    "$\\text{Batch Size} \\longrightarrow \\text{Hyperparameter}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13fc6c",
   "metadata": {},
   "source": [
    "- if want to see 3D visualization of gradient descent go to : [lillpads/gradient_descent_viz](lillpads/gradient_descent_viz)\n",
    "\n",
    "- **Book:** Deep learning with Python Second Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd9127",
   "metadata": {},
   "source": [
    "$Q.$ How to decide the batch size ?\n",
    "\n",
    "$\\longrightarrow$\n",
    "\n",
    "1.\n",
    "$$\n",
    "{\\text{GPU}} \\longrightarrow \n",
    "\\frac{\\text{V RAM}}{\\text{virtual RAM}} \\longrightarrow \n",
    "\\begin{cases}\n",
    "\\text{2 GB} \\\\\n",
    "\\text{4 GB} \\\\\n",
    "\\text{8 GB} \\\\\n",
    "\\text{16 GB} \\\\\n",
    "\\text{32 GB} \\\\\n",
    "\\end{cases}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87cc3c",
   "metadata": {},
   "source": [
    "2. \n",
    "\n",
    "$(2^{n}) \\text{ why ?}$\n",
    "\n",
    "$\\longrightarrow$ GPU VRAM Hardware is designed by Nvidia\n",
    "\n",
    "Major GPU provider are:\n",
    "1. Nvidia\n",
    "2. AMD\n",
    "\n",
    "**overclocking:** using $\\text{100\\%} $ of resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e194786",
   "metadata": {},
   "source": [
    "AMD | NVIDIA\n",
    "---|---\n",
    "overclocking built in | overclocking is not builtin (we have to perform some hacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc7afcd",
   "metadata": {},
   "source": [
    "$Q.$ Why GPU is costly ?\n",
    "\n",
    "1. Deep Learning\n",
    "2. Gaming\n",
    "3. Video Editing/ Rendering\n",
    "4. Crypto mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f4327",
   "metadata": {},
   "source": [
    "**<u>Optimization in DL:</u>**\n",
    "\n",
    "For task \n",
    "\n",
    "$$\n",
    "\\text{V RAM Allocation} \\longrightarrow (2)^{n} \\\\\n",
    "\n",
    "= 4, 8, 16, 32, 64, 128, 256, 512, 1024\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef275976",
   "metadata": {},
   "source": [
    "**<u>Kernel Selection:</u>** $\\longrightarrow (2)^{n}$\n",
    "\n",
    "Generally have even number $2^{n}$\n",
    "\n",
    "odd number will not work out to full memory allocation $2^{n} -$ will work efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df3da6",
   "metadata": {},
   "source": [
    "### 2] SGD with Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245bca7",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{new} = w_{old} - \\eta \\cdot \\frac{\\partial L}{\\partial w_{old}} \\\\\n",
    "\n",
    "b_{new} = b_{old} - \\eta \\cdot \\frac{\\partial L}{\\partial b_{old}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d1c92",
   "metadata": {},
   "source": [
    "rewrite the above equations w.r.t time dimention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144f344",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{t} = w_{t-1} - \\eta \\cdot \\frac{\\partial L}{\\partial w_{t-1}} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d69dee",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{t-2, t-1}{old} ,\\frac{t}{current} ,\\frac{t+1, t+2}{future} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "t-1 \\longrightarrow t\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{t-1} \\approx w_{t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{impact of } w_{t-1} \\text{ in the output of } w_{t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f2b2d",
   "metadata": {},
   "source": [
    "##### **<u>Time Series:</u>** $\\text{Removal of} \\longrightarrow \\text{Noise/ Jitter/ Oscillations}$\n",
    "\n",
    "1] Exponential Weighted Average\n",
    "\n",
    "2] Rolling Mean (no use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f6a77",
   "metadata": {},
   "source": [
    "##### **1] Exponential Weighted Average (EWA)</u>** *Smoothing*\n",
    "\n",
    "$Time: t_1, t_2, t_3, t_4, ......, t_n$\n",
    "\n",
    "$Values: a_1, a_2, a_3, a_4, ......, a_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08948e6",
   "metadata": {},
   "source": [
    "![Time Vs Values](../results/ewa_smoothing_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ab16a",
   "metadata": {},
   "source": [
    "$t_1 \\text{ should be controlling } t_2$\n",
    "\n",
    "we need a controlling part\n",
    "\n",
    "$$\n",
    "\\text{EWA } V_{t_2} = \\beta \\cdot V_{t_1} + ( ( 1 - \\beta) \\cdot V_{t_2})\n",
    "$$\n",
    "\n",
    "main formula to keep in mind.\n",
    "\n",
    "$\\text{Recommended }  \\beta \\text{ value should be clode to 1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05664831",
   "metadata": {},
   "source": [
    "Let's putting $\\beta = 0.95$ in formula of EWA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424d029",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{EWA } V_{t_2}  &= ( 0.95 * a_1) + ( (1 - 0.95) * a_2) \\\\\n",
    "  &= \\frac{0.95 * a_1}{\\text{High Impact}} + \\frac{0.05 * a_2 }{\\text{Low Impact}} \n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1b9429",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{EWA } V_{t_3} &= \\beta \\cdot V_{t_2} + ( ( 1 - \\beta) \\cdot V_{t_3})\\\\\n",
    "&= 0.95 \\cdot \\text{EWA of } V_{t_2} + ( 1 - \\beta) \\cdot a_{3}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578071c9",
   "metadata": {},
   "source": [
    "> Normal use of optimizer is on regresison type problem\n",
    "\n",
    "[But](), $\\text{``When we start working with non linear data SGD + momentum is our choice.``}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41086cdf",
   "metadata": {},
   "source": [
    "$\\text{Momentum is the push towards }$ [Global Minima]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e67728",
   "metadata": {},
   "source": [
    "![Plateau State](../results/plateau_state.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7a807",
   "metadata": {},
   "source": [
    "if we stuck here , even after 20-30 epochs, it needs push so momentum is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a95b9",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textcolor{red}{\\underline{\\text{Plateau Region Problem}}}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\textcolor{blue}{\\text{Very common in deep learning}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b805a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ed1ae1b",
   "metadata": {},
   "source": [
    "$\\textcolor{red}{\\underline{\\text{Advantages of SGD + momentum}}}$\n",
    "\n",
    "1. Noise Reducation\n",
    "2. Smoothing of the noise\n",
    "3. Smooth Convergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f136fd2e",
   "metadata": {},
   "source": [
    "### 3] Adagrad (Adaptive Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ac79b",
   "metadata": {},
   "source": [
    "till now we have seen that learning rate was fixed\n",
    "\n",
    "$$\n",
    "\\text{Learning Rate} = \\eta = Fixed\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88490065",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{n} = w_{o} - \\eta \\cdot \\frac{\\partial L}{\\partial w_{o}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{n} = w_{o} - \\eta^{`} \\cdot \\frac{\\partial L}{\\partial w_{o}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\eta^{`} = \\frac{\\eta}{\\sqrt{\\alpha^{t} + \\epsilon}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e97047",
   "metadata": {},
   "source": [
    "$\\epsilon$ : $\\textcolor{red}{\\text{very small value}}$, to avoide divide by zero error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6549c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\alpha^{t} = \\sum^{t}_{i=1} {\\frac{\\partial L}{\\partial w_{t}}}^{2} = \\text{Slope Squared} = \\text{Very Large Value}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796c739",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Adaptive Learning} \\longrightarrow \\text{Dynamic Learning Rate}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc4503",
   "metadata": {},
   "source": [
    "- when we start we need high learning rate\n",
    "- When we converge we need lower learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe67e6",
   "metadata": {},
   "source": [
    "$\\textcolor{red}{\\text{we want that when we start we should take big steps and as we reaching to local minima, we should take small steps}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4249bc",
   "metadata": {},
   "source": [
    "we want to make \n",
    "\n",
    "$$\n",
    "\\eta^{`} = \\frac{\\eta}{\\text{Large Value}} \\\\\n",
    ".\\\\\n",
    ".\\\\ \n",
    "\\text{Requirement:}\\\\\n",
    "\\text{it full-fills the}\\\\\n",
    "\\text{requirement}\\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    "\n",
    "\\downarrow\\\\\n",
    "\n",
    "\\eta^{`} = \\text{Small Value}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb317bd",
   "metadata": {},
   "source": [
    "$\\textcolor{red}{\\underline{\\text{Dis-Advantages:}}}$\n",
    "\n",
    "1. Slow Convergence (very slow update): only in the end, it is good but we won't use alote.\n",
    "\n",
    "2. $\\textcolor{red}{\\underline{\\eta^{`} =}}$ Possibility to come $\\alpha$ will be very small, so $\\alpha^{t} \\approx 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3d468",
   "metadata": {},
   "source": [
    "$\\textcolor{red}{\\underline{\\text{Note:-}}}$ \n",
    "- SGD with momentum (Academically)\n",
    "- Adam (Industry Applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8c008",
   "metadata": {},
   "source": [
    "Loss tracking is good in SGD not good in Adam, cause it is faster in convergence & in industry we want fast results , but in academics we want to test alot, so need track on loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc6156",
   "metadata": {},
   "source": [
    "### 4] RMS Prop (Root Mean Squared Propogation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da1e41",
   "metadata": {},
   "source": [
    "In Adaptive (Adagrade) Learning, we kept $\\textcolor{red}{\\epsilon}$ not just to avoid divide by zero error, there's more to it, cause there has to be a reason for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc27d0",
   "metadata": {},
   "source": [
    "Initially when researchers working with $\\eta^{`}$ formula they understood  that this perticular value $\\alpha^{t}$ comes actually close to zero, like $0.000000.....$ lot of zero & then some value but a very small value $\\alpha^{t}$ was taking this is the thing we will be addressing here (it was causing slow convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd171d7e",
   "metadata": {},
   "source": [
    "RMS Prop is also dependent on sma ething .which is **EWA** (Explonential Weighted Average) similar to old one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add3b5b",
   "metadata": {},
   "source": [
    "In Adagrad we made learning rate dynamic, Sosimilarlly in RMS prop learning rate will also dynamic, we won't be writing same formula, So lets start with\n",
    "\n",
    "$$\n",
    "\\eta^{`} = \\frac{\\eta}{\\sqrt{Sd_{wt} + \\epsilon}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77d926",
   "metadata": {},
   "source": [
    "A term introduced here\n",
    "\n",
    "$Q.$ What is $Sd_{wt}$ ?\n",
    "\n",
    "$\\longrightarrow$ It is aso w.r.t time initially $Sd_{we} = 0$ an then in next step \n",
    "\n",
    "\\begin{align*}\n",
    "Sd_{wt1} &= \\beta \\cdot Sd_{wt-1} + (1 - \\beta) \\cdot Sd_{wt1}\\\\\n",
    "\n",
    "&= \\beta \\cdot Sd_{wt-1} + (1 - \\beta) \\cdot (\\frac{\\partial L}{\\partial w_{t}})^{2}\n",
    "\\end{align*}\n",
    "\n",
    "- you can see the major change that we made here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9866938",
   "metadata": {},
   "source": [
    "if we compare\n",
    "\n",
    "$\n",
    "\\text{1. SGD with momentum} \\longrightarrow \\text{No Dynamic Learning Rate}\\\\\n",
    "\\text{2. Adagrad} \\longrightarrow \\text{Dynamic Learning Rate}\\\\\n",
    "\\text{3. RMS Prop} \\longrightarrow \\text{SGD with momentum + Dynamic Learning Rate in Exponential Weighted Avg L.R form}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d538b4e",
   "metadata": {},
   "source": [
    "if we compare Adagrad Vs RMS Prop\n",
    "\n",
    "1. RMS Prop converges very slower at end w.r.t Adagrad.\n",
    "\n",
    "2. RMS Prop has less jittery ness or can say less oscillactions w.r.t Adagrad.\n",
    "\n",
    "there are 3 optimizaers are widely used in market\n",
    "\n",
    "1. SGD with Momentum\n",
    "2. RMS Prop\n",
    "3. Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e89e22",
   "metadata": {},
   "source": [
    "### 5] Adam Optimizer (Adaptive momentum Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69a730",
   "metadata": {},
   "source": [
    "Adaptive momentum estimator, Adam comprises two things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338dcb7",
   "metadata": {},
   "source": [
    "$\\text{RMS Prop + SGD with Momentum}$ \n",
    "\n",
    "$\\text{Dynamic Learning Rate + SGD with Momentum}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb6580",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{t} = w_{t-1} + \\eta^{`} \\cdot V_{dw_{t}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc371bd",
   "metadata": {},
   "source": [
    "where, \n",
    "\n",
    "$V_{dw_{t}} = \\beta \\cdot V_{dw_{t-1}} + (1 - \\beta) \\cdot (\\frac{\\partial L}{\\partial w_{t}}) \\quad \\textcolor{red}{\\text{* no square term}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b5ee1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\eta^{`} = \\frac{\\eta}{\\sqrt{Sd_{wt} + \\epsilon}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705bdd6",
   "metadata": {},
   "source": [
    "<u>Bias Calculateion</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260676ab",
   "metadata": {},
   "source": [
    "$$\n",
    "b_{t} = b_{t-1} + \\eta^{`} \\cdot V_{db_{t}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b17ec2",
   "metadata": {},
   "source": [
    "where, \n",
    "\n",
    "$V_{db_{t}} = \\beta \\cdot V_{db_{t-1}} + (1 - \\beta) \\cdot (\\frac{\\partial L}{\\partial b_{t}}) \\quad \\textcolor{red}{\\text{* no square term}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887487c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\eta^{`} = \\frac{\\eta}{\\sqrt{Sd_{bt} + \\epsilon}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b53c8",
   "metadata": {},
   "source": [
    "$\\textcolor{red}{\\text{* Learning Rate Scheduler}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b0915",
   "metadata": {},
   "source": [
    "Eposh = 100, Dynamic Learning Rate\n",
    "\n",
    "Prior to Dynamic Learning Rate, people used to handle it by simple python script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93764d",
   "metadata": {},
   "source": [
    "```python\n",
    "epochs = 100\n",
    "\n",
    "if epochs <= 25:\n",
    "    lr = 0.01\n",
    "elif epochs > 25 & epochs <= 30:\n",
    "    lr = 0.001\n",
    "elif epochs > 50 & epochs <=> 75:\n",
    "    lr = 0.0001\n",
    "else: # epochs > 75\n",
    "    lr = 0.00001\n",
    "```\n",
    "\n",
    "This reference to learning rate scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc98a40",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "- [https://www.ruder.io/tag/optimization/](https://www.ruder.io/tag/optimization/)\n",
    "\n",
    "    - Optimization for Deep Learning Highlights in 2017\n",
    "    - An overview of gradient descent optimization algorithms"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
